2025-03-02 15:38:22,359 - train - INFO - Starting training for 3000 episodes with agent type: PPOAgent
2025-03-02 15:38:22,360 - train - INFO - Agent config: {'obs_dim': 35, 'action_dim': 37, 'hidden_dims': [256, 128, 64], 'learning_rate': 0.0005, 'min_learning_rate': 3e-05, 'gamma': 0.99, 'gae_lambda': 0.95, 'policy_clip': 0.2, 'value_coef': 0.5, 'entropy_coef': 0.003917972988552537, 'batch_size': 64, 'update_frequency': 2048, 'max_grad_norm': 0.5, 'update_counter': 55, 'step_counter': 1446, 'total_training_steps': 1000000, 'current_lr': 0.0004854225556933979, 'device': 'cuda', 'memory_size': 1446, 'avg_policy_loss': 0.0, 'avg_value_loss': 0.0, 'avg_entropy': 0.0, 'avg_reward': 7.4385}
2025-03-02 15:38:24,255 - train - INFO - Episode 100/3000 | Reward: 2.69 | Length: 8.05 | Loss: 0.0000
2025-03-02 15:38:25,203 - train - INFO - Evaluation at episode 100: 4.00 reward, Win rate: 0.73
2025-03-02 15:38:26,635 - train - INFO - Episode 200/3000 | Reward: 2.03 | Length: 8.42 | Loss: 0.0000
2025-03-02 15:38:27,608 - train - INFO - Evaluation at episode 200: 4.00 reward, Win rate: 0.87
2025-03-02 15:38:27,608 - train - INFO - Win rate 0.87 is above threshold 0.75 (1/2)
2025-03-02 15:38:27,616 - train - INFO - Training stopped early by callback at episode 200
2025-03-02 15:38:27,617 - train - INFO - Training completed!
2025-03-02 15:38:28,912 - train - INFO - Final evaluation: 2.05 reward
