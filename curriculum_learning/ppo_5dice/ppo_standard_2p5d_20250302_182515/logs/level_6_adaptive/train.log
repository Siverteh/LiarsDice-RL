2025-03-02 19:48:19,745 - train - INFO - Starting training for 26000 episodes with agent type: PPOAgent
2025-03-02 19:48:19,745 - train - INFO - Agent config: {'obs_dim': 47, 'action_dim': 61, 'hidden_dims': [1024, 512, 256, 128, 64], 'learning_rate': 0.0003, 'min_learning_rate': 3e-05, 'gamma': 0.99, 'gae_lambda': 0.95, 'policy_clip': 0.2, 'value_coef': 0.5, 'entropy_coef': 0.002, 'batch_size': 64, 'update_frequency': 4096, 'max_grad_norm': 0.5, 'update_counter': 82, 'step_counter': 3496, 'total_training_steps': 1000000, 'current_lr': 0.00023149398917377166, 'device': 'cuda', 'memory_size': 948, 'avg_policy_loss': 0.0, 'avg_value_loss': 0.0, 'avg_entropy': 0.0, 'avg_reward': 9.3135}
2025-03-02 19:48:23,296 - train - INFO - Episode 100/26000 | Reward: 2.94 | Length: 15.81 | Loss: 0.0000
2025-03-02 19:48:38,918 - train - INFO - Evaluation at episode 100: 4.00 reward, Win rate: 0.90
2025-03-02 19:48:38,918 - train - INFO - Win rate 0.90 is above threshold 0.75 (1/3)
2025-03-02 19:48:41,998 - train - INFO - Episode 200/26000 | Reward: 2.97 | Length: 15.45 | Loss: 0.0000
2025-03-02 19:48:57,291 - train - INFO - Evaluation at episode 200: 2.00 reward, Win rate: 0.93
2025-03-02 19:48:57,291 - train - INFO - Win rate 0.93 is above threshold 0.75 (2/3)
2025-03-02 19:49:00,376 - train - INFO - Episode 300/26000 | Reward: 2.85 | Length: 15.73 | Loss: 0.0000
2025-03-02 19:49:16,034 - train - INFO - Evaluation at episode 300: -5.00 reward, Win rate: 0.83
2025-03-02 19:49:16,035 - train - INFO - Win rate 0.83 is above threshold 0.75 (3/3)
2025-03-02 19:49:16,035 - train - INFO - Early stopping triggered at episode 300 with win rate 0.83
2025-03-02 19:49:16,054 - train - INFO - Training completed!
2025-03-02 19:49:45,319 - train - INFO - Final evaluation: 2.65 reward
