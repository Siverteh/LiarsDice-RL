2025-03-02 15:38:12,868 - train - INFO - Starting training for 3000 episodes with agent type: PPOAgent
2025-03-02 15:38:12,868 - train - INFO - Agent config: {'obs_dim': 35, 'action_dim': 37, 'hidden_dims': [256, 128, 64], 'learning_rate': 0.0005, 'min_learning_rate': 3e-05, 'gamma': 0.99, 'gae_lambda': 0.95, 'policy_clip': 0.2, 'value_coef': 0.5, 'entropy_coef': 0.003958780924479187, 'batch_size': 64, 'update_frequency': 2048, 'max_grad_norm': 0.5, 'update_counter': 54, 'step_counter': 737, 'total_training_steps': 1000000, 'current_lr': 0.00048594252378432185, 'device': 'cuda', 'memory_size': 144, 'avg_policy_loss': 0.0, 'avg_value_loss': 0.0, 'avg_entropy': 0.0, 'avg_reward': 9.221}
2025-03-02 15:38:14,127 - train - INFO - Episode 100/3000 | Reward: 2.09 | Length: 7.11 | Loss: 0.0000
2025-03-02 15:38:15,015 - train - INFO - Evaluation at episode 100: 4.00 reward, Win rate: 0.57
2025-03-02 15:38:16,575 - train - INFO - Episode 200/3000 | Reward: 2.16 | Length: 6.73 | Loss: 0.0000
2025-03-02 15:38:17,391 - train - INFO - Evaluation at episode 200: 5.00 reward, Win rate: 0.70
2025-03-02 15:38:18,494 - train - INFO - Episode 300/3000 | Reward: 2.07 | Length: 6.87 | Loss: 0.0000
2025-03-02 15:38:19,336 - train - INFO - Evaluation at episode 300: 4.00 reward, Win rate: 0.73
2025-03-02 15:38:20,481 - train - INFO - Episode 400/3000 | Reward: 2.17 | Length: 6.87 | Loss: 0.0000
2025-03-02 15:38:21,305 - train - INFO - Evaluation at episode 400: 3.00 reward, Win rate: 0.83
2025-03-02 15:38:21,305 - train - INFO - Win rate 0.83 is above threshold 0.75 (1/2)
2025-03-02 15:38:21,312 - train - INFO - Training stopped early by callback at episode 400
2025-03-02 15:38:21,313 - train - INFO - Training completed!
2025-03-02 15:38:22,357 - train - INFO - Final evaluation: 2.16 reward
