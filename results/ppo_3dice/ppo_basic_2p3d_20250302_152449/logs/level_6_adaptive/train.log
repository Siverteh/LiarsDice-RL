2025-03-02 15:33:52,253 - train - INFO - Starting training for 10000 episodes with agent type: PPOAgent
2025-03-02 15:33:52,253 - train - INFO - Agent config: {'obs_dim': 35, 'action_dim': 37, 'hidden_dims': [256, 128, 64], 'learning_rate': 0.0005, 'min_learning_rate': 3e-05, 'gamma': 0.99, 'gae_lambda': 0.95, 'policy_clip': 0.2, 'value_coef': 0.5, 'entropy_coef': 0.0038363571166992374, 'batch_size': 64, 'update_frequency': 2048, 'max_grad_norm': 0.5, 'update_counter': 57, 'step_counter': 216, 'total_training_steps': 1000000, 'current_lr': 0.00048435523605567534, 'device': 'cuda', 'memory_size': 1008, 'avg_policy_loss': 0.0, 'avg_value_loss': 0.0, 'avg_entropy': 0.0, 'avg_reward': 8.657500000000002}
2025-03-02 15:33:53,606 - train - INFO - Episode 100/10000 | Reward: 2.95 | Length: 7.63 | Loss: 0.0000
2025-03-02 15:33:55,270 - train - INFO - Evaluation at episode 100: 5.00 reward, Win rate: 0.90
2025-03-02 15:33:55,270 - train - INFO - Win rate 0.90 is above threshold 0.75 (1/3)
2025-03-02 15:33:56,692 - train - INFO - Episode 200/10000 | Reward: 3.30 | Length: 8.04 | Loss: 0.0000
2025-03-02 15:33:58,376 - train - INFO - Evaluation at episode 200: 4.00 reward, Win rate: 0.93
2025-03-02 15:33:58,376 - train - INFO - Win rate 0.93 is above threshold 0.75 (2/3)
2025-03-02 15:34:00,544 - train - INFO - Episode 300/10000 | Reward: 3.36 | Length: 7.97 | Loss: 0.0000
2025-03-02 15:34:02,284 - train - INFO - Evaluation at episode 300: 3.00 reward, Win rate: 0.90
2025-03-02 15:34:02,285 - train - INFO - Win rate 0.90 is above threshold 0.75 (3/3)
2025-03-02 15:34:02,285 - train - INFO - Early stopping triggered at episode 300 with win rate 0.90
2025-03-02 15:34:02,330 - train - INFO - Training completed!
2025-03-02 15:34:04,714 - train - INFO - Final evaluation: 3.35 reward
